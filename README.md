# Map-Reduce LLM Pipeline for Meeting Transcripts

Extract and validate action items from long meeting transcripts using LangChain's Map-Reduce chain pattern.

## üéØ Project Overview

Built a multi-stage Map‚ÄìReduce LLM pipeline using LangChain to extract and validate action items from long meeting transcripts.

### Output Schema
```json
{
  "task": "",
  "owner": "",
  "deadline": "",
  "confidence": 0.0
}
```

## üìÅ Project Structure

```
Map-Reduce-Chain/
‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # Pydantic models (ActionItem schema)
‚îÇ   ‚îú‚îÄ‚îÄ transcript_processor.py   # Transcript ingestion & chunking
‚îÇ   ‚îú‚îÄ‚îÄ map_phase.py              # MAP: Extract action items
‚îÇ   ‚îú‚îÄ‚îÄ reduce_phase.py           # REDUCE: Consolidate & deduplicate
‚îÇ   ‚îú‚îÄ‚îÄ confidence_scorer.py      # Confidence scoring layer
‚îÇ   ‚îú‚îÄ‚îÄ validation.py             # Edge case handling & validation
‚îÇ   ‚îî‚îÄ‚îÄ main.py                   # Orchestration logic
‚îú‚îÄ‚îÄ tests/                        # Unit & integration tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_map_phase.py
‚îÇ   ‚îú‚îÄ‚îÄ test_reduce_phase.py
‚îÇ   ‚îú‚îÄ‚îÄ test_confidence_scorer.py
‚îÇ   ‚îî‚îÄ‚îÄ test_validation.py
‚îú‚îÄ‚îÄ data/                         # Data folder
‚îÇ   ‚îú‚îÄ‚îÄ transcripts/              # Sample transcripts
‚îÇ   ‚îî‚îÄ‚îÄ outputs/                  # Generated action items
‚îú‚îÄ‚îÄ notebooks/                    # Exploration & demos
‚îÇ   ‚îî‚îÄ‚îÄ exploration.ipynb
‚îú‚îÄ‚îÄ requirements.txt              # Project dependencies
‚îú‚îÄ‚îÄ .gitignore                    # Git ignore rules
‚îú‚îÄ‚îÄ .env.example                  # Environment template
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üöÄ Quick Start

### 1. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Set Up Environment Variables

```bash
# Copy the example to .env
cp .env.example .env

# Edit .env and add your OpenAI API key
# OPENAI_API_KEY=sk-...
```

### 4. Run Tests

```bash
pytest tests/ -v
```

## üìÖ Implementation Timeline

### Day 1: Core Extraction (MAP Phase)
- ‚úÖ Define action item schema
- ‚úÖ Transcript ingestion & metadata handling
- ‚úÖ Smart chunking (by speaker turns, 1-2 minutes)
- ‚úÖ MAP prompt + LangChain chain
- ‚úÖ Output validation & retry logic

### Day 2: Consolidation (REDUCE Phase)
- ‚úÖ Merge logic definition
- ‚úÖ REDUCE prompt + chain
- ‚úÖ Confidence scoring layer
- ‚úÖ Edge case handling
- ‚úÖ UI/CLI implementation
- ‚úÖ Documentation

## üß† Key LangChain Concepts Used

- **Map-Reduce Chains**: Split, process, and consolidate
- **PromptTemplate**: Reusable prompt patterns
- **LLMChain**: Chain prompts with LLM calls
- **PydanticOutputParser**: Structured extraction
- **Document Objects**: Metadata-aware text processing
- **Custom Text Splitters**: Preserve speaker context
- **Retry & Validation**: Reliability patterns

## üìù Usage Examples

### Extract from a transcript file

```python
from src.main import extract_action_items

items = extract_action_items("path/to/transcript.txt")
for item in items:
    print(f"Task: {item.task}")
    print(f"Owner: {item.owner}")
    print(f"Confidence: {item.confidence}")
```

### Using the CLI

```bash
python src/main.py process --input transcript.txt --output actions.json
```

### Using Streamlit UI

```bash
streamlit run src/app.py
```

## üîß Configuration

Edit `src/config.py` to customize:

- `LOG_LEVEL`: DEBUG, INFO, WARNING, ERROR
- `BATCH_SIZE`: Number of chunks to process at once
- `CONFIDENCE_THRESHOLD`: Minimum confidence score (0-1)
- `MODEL_NAME`: LLM to use (gpt-4, gpt-3.5-turbo)

## ‚úÖ Testing

Run all tests:
```bash
pytest tests/ -v
```

Run specific test:
```bash
pytest tests/test_map_phase.py -v
```

With coverage:
```bash
pytest tests/ --cov=src --cov-report=html
```

## üìö Architecture Notes

### Why Map-Reduce?

1. **Scalability**: Process transcripts of any length
2. **Reliability**: LLM operates on focused contexts
3. **Debuggability**: Each stage is testable independently
4. **Flexibility**: Easy to add validation layers

### Workflow

```
Raw Transcript
     ‚Üì
[Ingestion] ‚Üí Add metadata, normalize
     ‚Üì
[Chunking] ‚Üí Speaker turns, preserve context
     ‚Üì
[MAP Phase] ‚Üí Extract candidates from each chunk
     ‚Üì
[REDUCE Phase] ‚Üí Deduplicate, fill gaps, normalize
     ‚Üì
[Confidence Scoring] ‚Üí Rate certainty
     ‚Üì
[Validation] ‚Üí Handle edge cases
     ‚Üì
Structured Action Items
```

## üö® Known Limitations

- Requires clear speaker labels in transcript
- Performance degrades on very long transcripts (>1hr) without chunking optimization
- Confidence scores are heuristic-based
- LLM hallucinations possible on ambiguous deadlines

## ü§ù Contributing

1. Create a feature branch
2. Write tests for new features
3. Run `black` and `flake8` before committing
4. Update README if adding new functionality


**Built with**: LangChain, OpenAI, Pydantic, Streamlit
