# Map-Reduce LLM Pipeline for Meeting Transcripts

Extract and validate action items from long meeting transcripts using LangChain's Map-Reduce chain pattern.

## üéØ Project Overview

Built a multi-stage Map‚ÄìReduce LLM pipeline using LangChain to extract and validate action items from long meeting transcripts.

### Output Schema
```json
{
  "task": "",
  "owner": "",
  "deadline": "",
  "confidence": 0.0
}
```

## üìÅ Project Structure

```text
Map-Reduce-Chain/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ document_loader.py        # LangChain Documents + metadata
‚îÇ   ‚îú‚îÄ‚îÄ map_chain.py              # MAP chain (Prompt + LLM + Parser)
‚îÇ   ‚îú‚îÄ‚îÄ reduce_chain.py           # REDUCE chain
‚îÇ   ‚îú‚îÄ‚îÄ confidence_chain.py       # Confidence scoring chain
‚îÇ   ‚îú‚îÄ‚îÄ validation.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Pipeline orchestration
‚îÇ   ‚îî‚îÄ‚îÄ prompts/
‚îÇ       ‚îú‚îÄ‚îÄ map_prompt.yaml
‚îÇ       ‚îî‚îÄ‚îÄ reduce_prompt.yaml
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Quick Start

### 1. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Set Up Environment Variables

```bash
# Copy the example to .env
cp .env.example .env

# Edit .env and add your OpenAI API key
# OPENAI_API_KEY=sk-...
```

### 4. Run Tests

```bash
pytest tests/ -v
```

## üìÖ Implementation Timeline

### Day 1: Core Extraction (MAP Phase)
- ‚úÖ Define action item schema
- ‚úÖ Transcript ingestion & metadata handling
- ‚úÖ Smart chunking (by speaker turns, 1-2 minutes)
- ‚úÖ MAP prompt + LangChain chain
- ‚úÖ Output validation & retry logic

### Day 2: Consolidation (REDUCE Phase)
- ‚úÖ Merge logic definition
- ‚úÖ REDUCE prompt + chain
- ‚úÖ Confidence scoring layer
- ‚úÖ Edge case handling
- ‚úÖ UI/CLI implementation
- ‚úÖ Documentation

## üß† Key LangChain Concepts Used

- **Map-Reduce Chains**: Split, process, and consolidate
- **PromptTemplate**: Reusable prompt patterns
- **LLMChain**: Chain prompts with LLM calls
- **PydanticOutputParser**: Structured extraction
- **Document Objects**: Metadata-aware text processing
- **Custom Text Splitters**: Preserve speaker context
- **Retry & Validation**: Reliability patterns

## üìù Usage Examples

### Extract from a transcript file

```python
from src.main import ActionItemExtractor

extractor = ActionItemExtractor()
items = extractor.extract("path/to/transcript.txt", "meeting_001")
for item in items:
     print(f"Task: {item.task}")
     print(f"Owner: {item.owner}")
     print(f"Confidence: {item.confidence}")
```

### Using the CLI

```bash
python src/main.py transcript.txt actions.json
```

### Using Streamlit UI

```bash
streamlit run src/app.py
```

## üîß Configuration

Edit `src/config.py` to customize:

- `LOG_LEVEL`: DEBUG, INFO, WARNING, ERROR
- `BATCH_SIZE`: Number of chunks to process at once
- `CONFIDENCE_THRESHOLD`: Minimum confidence score (0-1)
- `OPENAI_MODEL`: LLM to use (gpt-4, gpt-3.5-turbo)

## ‚úÖ Testing

Run all tests:
```bash
pytest tests/ -v
```

Run specific test:
```bash
pytest tests/ -k map -v
```

With coverage:
```bash
pytest tests/ --cov=src --cov-report=html
```

## üìö Architecture Notes

### Why Map-Reduce?

1. **Scalability**: Process transcripts of any length
2. **Reliability**: LLM operates on focused contexts
3. **Debuggability**: Each stage is testable independently
4. **Flexibility**: Easy to add validation layers

### Workflow

```
Raw Transcript
     ‚Üì
[Ingestion] ‚Üí Add metadata, normalize
     ‚Üì
[Chunking] ‚Üí Speaker turns, preserve context
     ‚Üì
[MAP Phase] ‚Üí Extract candidates from each chunk
     ‚Üì
[REDUCE Phase] ‚Üí Deduplicate, fill gaps, normalize
     ‚Üì
[Confidence Scoring] ‚Üí Rate certainty
     ‚Üì
[Validation] ‚Üí Handle edge cases
     ‚Üì
Structured Action Items
```

## üö® Known Limitations

- Requires clear speaker labels in transcript
- Performance degrades on very long transcripts (>1hr) without chunking optimization
- Confidence scores are heuristic-based
- LLM hallucinations possible on ambiguous deadlines

## ü§ù Contributing

1. Create a feature branch
2. Write tests for new features
3. Run `black` and `flake8` before committing
4. Update README if adding new functionality


**Built with**: LangChain, OpenAI, Pydantic, Streamlit
